{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학우 보이스 데이터 기반 고민 상담 챗봇\n",
    "##### 데이터 출처 - 정의중님, 최동현님 목소리\n",
    "##### 참고 사이트 - https://github.com/coqui-ai/TTS?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audio-recorder-streamlit\n",
      "  Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: streamlit>=1.12.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from audio-recorder-streamlit) (1.49.1)\n",
      "Collecting altair<5 (from audio-recorder-streamlit)\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting entrypoints (from altair<5->audio-recorder-streamlit)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from altair<5->audio-recorder-streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from altair<5->audio-recorder-streamlit) (4.25.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from altair<5->audio-recorder-streamlit) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.18 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from altair<5->audio-recorder-streamlit) (2.3.2)\n",
      "Collecting toolz (from altair<5->audio-recorder-streamlit)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from pandas>=0.18->altair<5->audio-recorder-streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from pandas>=0.18->altair<5->audio-recorder-streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from pandas>=0.18->altair<5->audio-recorder-streamlit) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair<5->audio-recorder-streamlit) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from referencing>=0.28.4->jsonschema>=3.0->altair<5->audio-recorder-streamlit) (4.15.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (6.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<26,>=20 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (25.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (6.32.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (6.5.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio-recorder-streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio-recorder-streamlit) (5.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm_env/lib/python3.12/site-packages (from jinja2->altair<5->audio-recorder-streamlit) (3.0.2)\n",
      "Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: toolz, entrypoints, altair, audio-recorder-streamlit\n",
      "\u001b[2K  Attempting uninstall: altair\n",
      "\u001b[2K    Found existing installation: altair 5.5.0\n",
      "\u001b[2K    Uninstalling altair-5.5.0:\n",
      "\u001b[2K      Successfully uninstalled altair-5.5.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [audio-recorder-streamlit]ecorder-streamlit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed altair-4.2.2 audio-recorder-streamlit-0.0.10 entrypoints-0.4 toolz-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install dotenv\n",
    "# !pip install openai\n",
    "# !pip install coqui-tts\n",
    "# !pip install hangul_romanize\n",
    "# !pip install pyobjc\n",
    "# !pip install ffmpeg\n",
    "# !pip install coqui-tts\n",
    "# !pip install audio-recorder-streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from pathlib import Path\n",
    "from TTS.api import TTS\n",
    "import speech_recognition as sr\n",
    "import tempfile, subprocess\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메인 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "\n",
    "base = Path(\"dataset/wavs\")\n",
    "ref_wavs = [str(base / f\"{i:04}.wav\") for i in range(1, 11)]\n",
    "\n",
    "system_instruction = \"\"\"\n",
    "        당신은 사용자의 고민 해결을 돕는 '고민 상담 봇'이야. 이름은 정의중이고, 다음 원칙을 반드시 지켜줘.\n",
    "\n",
    "        1. 핵심 행동 지침:\n",
    "\n",
    "        경청과 공감: 먼저 판단 없이 사용자의 고민을 듣고, \"그런 고민을 하고 있었구나\"라며 상황 자체를 인정하고 공감한다.\n",
    "\n",
    "        질문을 통한 탐색: \"어떤 점이 가장 힘들어?\", \"네가 진짜 원하는 건 뭐야?\" 와 같은 개방형 질문을 통해, 사용자가 자신의 생각과 감정을 스스로 깊이 들여다보게 한다.\n",
    "\n",
    "        스스로 답 찾기 지원: \"어떤 방법들이 있을 수 있을까?\"라고 질문하며 사용자가 직접 해결의 실마리를 찾도록 돕는다. 정답을 알려주지 않고 사용자의 가능성을 믿고 지지한다.\n",
    "\n",
    "        직접적인 해결책 제시: 사용자가 스스로 찾은 답을 기반으로 더 추가 위로 및 해결책 제시 (\"~하는 게 좋겠어\")\n",
    "\n",
    "        2. 절대 금지:\n",
    "\n",
    "        섣부른 판단, 충고, 평가\n",
    "\n",
    "        다른 사람과의 비교\n",
    "\n",
    "        고민의 경중을 함부로 단정하는 것 (\"그건 별거 아니야\")\n",
    "    \"\"\"\n",
    "\n",
    "def safe_play(seg: AudioSegment):\n",
    "    seg = seg.set_frame_rate(44100).set_channels(1)\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "        seg.export(f.name, format=\"wav\")\n",
    "        subprocess.run([\"afplay\", f.name], check=True)\n",
    "        \n",
    "def worry_man(temperature=0.3):\n",
    "    client = OpenAI()\n",
    "    messages = [{'role': 'system', 'content': system_instruction}]\n",
    "\n",
    "    out_path = Path(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/JeongUiJung_Answer.wav\")\n",
    "\n",
    "    print(\"고민상담맨 정의중님과 상담이 연결되었습니다. '종료'를 원하면 종료를 입력하세요.\")\n",
    "    sound_1 = AudioSegment.from_mp3(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_0.mp3\")\n",
    "    safe_play(sound_1)\n",
    "    \n",
    "    print(\"안녕, 나는 너의 친구 고민상담맨 정의중이야.\")\n",
    "    sound_2 = AudioSegment.from_wav(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_1.wav\")\n",
    "    safe_play(sound_2)\n",
    "    \n",
    "    print(\"오늘 무슨 고민이 있어서 날 찾은 거야?\")\n",
    "    sound_3 = AudioSegment.from_wav(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_2.wav\")\n",
    "    safe_play(sound_3)\n",
    "\n",
    "    while True:\n",
    "        recognizer = sr.Recognizer()\n",
    "        \n",
    "        with sr.Microphone() as source:\n",
    "            audio = recognizer.listen(source, timeout=5)\n",
    "            user_input = recognizer.recognize_google(audio, language='ko-KR')\n",
    "            \n",
    "            if user_input == '종료':\n",
    "                print('정의중: 오늘 이야기 나눠줘서 고마워. 여기서 마무리할게.')\n",
    "                sound_4 = AudioSegment.from_mp3(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_3.wav\")\n",
    "                safe_play(sound_4)\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "        messages.append({'role': 'user', 'content': f'고민: {user_input}'})\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=2048,\n",
    "            top_p=1,\n",
    "            frequency_penalty=1,\n",
    "            presence_penalty=1\n",
    "        )\n",
    "\n",
    "        assistant_text = response.choices[0].message.content\n",
    "\n",
    "        sentences = [s.strip() for s in re.split(r'(?<=[.!?。！？])\\s+', assistant_text) if s.strip()]\n",
    "        if not sentences:\n",
    "            sentences = [assistant_text.strip()]\n",
    "\n",
    "        full_text = \" \".join(sentences)\n",
    "        tts.tts_to_file(\n",
    "            text=full_text,\n",
    "            speaker_wav=ref_wavs,\n",
    "            language=\"ko\",\n",
    "            file_path=str(out_path)\n",
    "        )\n",
    "\n",
    "        audio = AudioSegment.from_wav(str(out_path))\n",
    "        safe_play(audio)\n",
    "\n",
    "        print(f'나: {user_input}\\n')\n",
    "        print(f'정의중: {assistant_text}\\n')\n",
    "        messages.append({'role': 'assistant', 'content': assistant_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고민상담맨 정의중님과 상담이 연결되었습니다. '종료'를 원하면 종료를 입력하세요.\n",
      "안녕, 나는 너의 친구 고민상담맨 정의중이야.\n",
      "오늘 무슨 고민이 있어서 날 찾은 거야?\n",
      "정의중: 그런 고민을 하고 있었구나. 무슨 일이 있었는지 조금 더 이야기해 줄 수 있어? 어떤 점이 가장 힘들어?\n",
      "\n",
      "나: 아 너무 속상해\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownValueError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworry_man\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mworry_man\u001b[39m\u001b[34m(temperature)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sr.Microphone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[32m     56\u001b[39m     audio = recognizer.listen(source, timeout=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     user_input = \u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mko-KR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user_input == \u001b[33m'\u001b[39m\u001b[33m종료\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     60\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m정의중: 오늘 이야기 나눠줘서 고마워. 여기서 마무리할게.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:262\u001b[39m, in \u001b[36mrecognize_legacy\u001b[39m\u001b[34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[39m\n\u001b[32m    255\u001b[39m response_text = obtain_transcription(\n\u001b[32m    256\u001b[39m     request, timeout=recognizer.operation_timeout\n\u001b[32m    257\u001b[39m )\n\u001b[32m    259\u001b[39m output_parser = OutputParser(\n\u001b[32m    260\u001b[39m     show_all=show_all, with_confidence=with_confidence\n\u001b[32m    261\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:134\u001b[39m, in \u001b[36mOutputParser.parse\u001b[39m\u001b[34m(self, response_text)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     actual_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_all:\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:183\u001b[39m, in \u001b[36mOutputParser.convert_to_result\u001b[39m\u001b[34m(response_text)\u001b[39m\n\u001b[32m    181\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[31mUnknownValueError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "worry_man(temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
